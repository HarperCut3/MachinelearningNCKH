# Decision-Centric Customer Retention
### *Precision Survival Analysis & Uplift Modeling for E-Commerce*

Implementation of a **Weibull AFT model** to predict *when* customers will churn â€” not just *if* â€” enabling proactive, perfectly-timed re-engagement interventions.

---

## ğŸš€ Overview
Most churn models ask "Will this customer leave next month?". This framework asks **"When will this customer leave, and what is the optimal time to intervene?"**

Key capabilities:
- **Survival Analysis**: Weibull AFT model (C-index > 0.76) predicts exact churn timing.
- **Uplift Modeling**: Uses T-Learner to identify "Persuadables" (customers who respond *only* if treated).
- **Decision Engine**: Calculates Expected Value of Intervention (EVI) to maximize ROI.
- **Interactive Dashboard**: Real-time risk profiling & portfolio management.

---

## âœ¨ Features
- **Precision Targeting**: Intervene only when hazard is high AND projected ROI is positive.
- **Explainable AI**: SHAP values explain *why* a customer is at risk.
- **Multi-Dataset Support**: UCI Online Retail, Ta Feng Grocery, and CDNOW datasets.
- **Cross-Validation**: Stratified K-Fold CV for survival model robustness.
- **Experiment Tracking**: MLflow integration for model metrics & artifact logging.
- **Comparison Reports**: Auto-generate cross-dataset performance comparisons.
- **Dockerized**: Production-ready container support.
- **Configurable**: Business rules centralized in YAML Configuration.

---

## ğŸ› ï¸ Installation

### 1. Prerequisites
- Python 3.10+
- Git

### 2. Setup
```bash
# Clone repository
git clone https://github.com/HarperCut3/MachinelearningNCKH.git
cd MachinelearningNCKH

# Create virtual environment (recommended)
python -m venv .venv
# Activate: Windows -> .venv\Scripts\activate | Linux/Mac -> source .venv/bin/activate

# Install dependencies
pip install -r requirements.txt

# For development (Jupyter, pytest):
pip install -r requirements-dev.txt
```

### 3. Data Setup
1. Download **Online Retail.xlsx** from [UCI ML Repository](https://archive.ics.uci.edu/dataset/352/online+retail).
2. Place it in `data/raw/Online Retail.xlsx`.

---

## ğŸš¦ Usage

### Run Pipeline
```bash
# Minimal run (fastest, ~2 mins)
python main.py --no-shap --no-mlflow

# Full run with SHAP analysis
python main.py

# Include Uplift Modeling (T-Learner)
python main.py --uplift

# Run on different datasets
python main.py --dataset cdnow --tau 90
python main.py --dataset tafeng --tau 60

# Enable Cross-Validation (5-fold)
python main.py --cv

# Full run with all features
python main.py --dataset uci --tau 90 --cv --uplift
```

### CLI Flags
| Flag | Default | Description |
|---|---|---|
| `--dataset` | `uci` | Dataset to use: `uci`, `tafeng`, or `cdnow` |
| `--tau` | `90` | Churn threshold in days |
| `--cv` | off | Enable 5-fold stratified cross-validation |
| `--uplift` | off | Enable T-Learner uplift modeling |
| `--no-shap` | off | Skip SHAP computation (faster) |
| `--no-mlflow` | off | Disable MLflow experiment tracking |

### Launch Dashboard
Start the interactive Streamlit app:
```bash
streamlit run app.py
# Access at http://localhost:8501
```

### Generate Comparison Report
Compare results across all dataset runs:
```bash
python src/comparison.py
```

---

## ğŸ“‚ Project Structure

```
MachinelearningNCKH/
â”œâ”€â”€ config/
â”‚   â””â”€â”€ simulation_params.yaml     # Business parameters (hazard threshold, costs, etc.)
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                       # Raw datasets (gitignored â€” download separately)
â”‚   â””â”€â”€ processed/                 # Feature cache (gitignored â€” auto-generated)
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_loader.py             # UCI Online Retail loader
â”‚   â”œâ”€â”€ data_loader_tafeng.py      # Ta Feng Grocery loader
â”‚   â”œâ”€â”€ data_loader_cdnow.py       # CDNOW loader
â”‚   â”œâ”€â”€ feature_engine.py          # Vectorized RFM + survival features
â”‚   â”œâ”€â”€ models.py                  # Weibull AFT, CoxPH, Logistic, RFM
â”‚   â”œâ”€â”€ policy.py                  # EVI Decision Engine
â”‚   â”œâ”€â”€ simulator.py               # Monte Carlo Simulation
â”‚   â”œâ”€â”€ evaluation.py              # C-index, IBS, AUC, business metrics
â”‚   â”œâ”€â”€ uplift.py                  # Uplift Modeling (T-Learner)
â”‚   â”œâ”€â”€ comparison.py              # Cross-run comparison report
â”‚   â””â”€â”€ visualization.py           # Publication-ready plots
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_components.py         # Unit tests for core modules
â”œâ”€â”€ outputs/                       # All pipeline outputs (gitignored)
â”‚   â””â”€â”€ {DATASET}_tau{N}/          # Isolated per-run output directory
â”‚       â”œâ”€â”€ figures/               # Generated plots
â”‚       â”œâ”€â”€ reports/               # intervention_decisions.csv
â”‚       â”œâ”€â”€ models/                # Serialized .pkl artifacts
â”‚       â””â”€â”€ logs/                  # Timestamped pipeline logs
â”œâ”€â”€ notebooks/                     # Jupyter exploration (gitignored)
â”œâ”€â”€ app.py                         # Streamlit Dashboard
â”œâ”€â”€ main.py                        # Pipeline Orchestrator
â”œâ”€â”€ Dockerfile                     # Container definition
â”œâ”€â”€ docker-compose.yml             # Dashboard + MLflow services
â”œâ”€â”€ requirements.txt               # Production dependencies
â”œâ”€â”€ requirements-dev.txt           # Dev/notebook dependencies
â””â”€â”€ README.md
```

---

## âš™ï¸ Configuration
Adjust business parameters in `config/simulation_params.yaml`:

```yaml
policy:
  hazard_threshold: 0.01    # Daily hazard trigger
  cost_per_contact: 1.0     # Cost per intervention (Â£)
  response_rate: 0.15       # Expected campaign success rate
```

---

## ğŸ“Š Key Results

### UCI Online Retail (n=4,338)
| Metric | Score | Target |
|---|---|---|
| **Weibull C-index (OOS)** | **0.829** | > 0.60 âœ… |
| **IBS Score** | **0.162** | < 0.25 âœ… |

### CDNOW (n=23,502)
| Metric | Score | Target |
|---|---|---|
| **Weibull C-index (OOS)** | **0.773** | > 0.60 âœ… |
| **IBS Score** | **0.077** | < 0.25 âœ… |
| **CV Mean C-index** | **0.746** | > 0.60 âœ… |

> **Monte Carlo Simulation**: The Weibull policy achieves significantly higher revenue precision per contact compared to standard RFM targeting, while reducing outreach costs by ~77%.

---

## ğŸ³ Docker Deployment

**Run everything (Dashboard + MLflow):**
```bash
docker compose up --build
```
- Dashboard: http://localhost:8501
- MLflow UI: http://localhost:5000

---

## ğŸ“ Citation
*D. Chen et al., "Data mining for the online retail industry: A case study of RFM model-based customer segmentation", 2012.*
